{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'path_to_train_images'\n",
    "val_dir = 'path_to_validation_images'\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3251 images belonging to 3 classes.\n",
      "Found 405 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "image_size = (300, 300)\n",
    "batch_size = 32\n",
    "\n",
    "train_dir = \"potato/Training\"\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=image_size,\n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "test_dir = \"potato/Testing\"\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                  target_size=image_size,\n",
    "                                                  batch_size=batch_size, \n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st layer CNN\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(300,300,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "\n",
    "    # 2nd layer CNN\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "\n",
    "    # 3rd layer CNN\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "\n",
    "    # 4th layer CNN\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "    # Add flatten layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "\n",
    "    \n",
    "    model.add(Dense(3, activation='softmax'))  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 298, 298, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 59, 59, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 57, 57, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 11, 11, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 9, 9, 512)         1180160   \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 4, 4, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,889,347\n",
      "Trainable params: 4,889,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 489s 5s/step - loss: 0.9495 - accuracy: 0.5451 - val_loss: 0.7383 - val_accuracy: 0.7086\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 641s 6s/step - loss: 0.7697 - accuracy: 0.6718 - val_loss: 0.6115 - val_accuracy: 0.7951\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 520s 5s/step - loss: 0.4275 - accuracy: 0.8364 - val_loss: 0.5432 - val_accuracy: 0.8173\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 1000s 10s/step - loss: 0.2954 - accuracy: 0.8871 - val_loss: 0.2293 - val_accuracy: 0.9235\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 516s 5s/step - loss: 0.1907 - accuracy: 0.9326 - val_loss: 0.2546 - val_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 443s 4s/step - loss: 0.1766 - accuracy: 0.9360 - val_loss: 0.1802 - val_accuracy: 0.9383\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 552s 5s/step - loss: 0.1378 - accuracy: 0.9523 - val_loss: 0.1998 - val_accuracy: 0.9531\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 452s 4s/step - loss: 0.1033 - accuracy: 0.9594 - val_loss: 0.1344 - val_accuracy: 0.9630\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 574s 6s/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.2360 - val_accuracy: 0.9111\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 621s 6s/step - loss: 0.0947 - accuracy: 0.9631 - val_loss: 0.1387 - val_accuracy: 0.9630\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_generator, epochs=10, validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model_2 - Neural Network with Optimizations\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Input Layer with L2 Regularization, matching image size (300x300) and 3 color channels\n",
    "model_2.add(Flatten(input_shape=(300, 300, 3)))  # Flattening the 300x300 image into 1D\n",
    "model_2.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))  # Regularized Dense Layer\n",
    "model_2.add(Dropout(0.5))  # Dropout layer to prevent overfitting\n",
    "\n",
    "# Hidden Layer with L2 Regularization\n",
    "model_2.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Output Layer\n",
    "output_classes = train_generator.num_classes  # Dynamically setting the number of classes\n",
    "model_2.add(Dense(output_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/102 [==============================] - 165s 2s/step - loss: 16.0999 - accuracy: 0.3676 - val_loss: 4.2529 - val_accuracy: 0.4025\n",
      "Epoch 2/10\n",
      "102/102 [==============================] - 57s 559ms/step - loss: 3.4198 - accuracy: 0.3931 - val_loss: 3.1021 - val_accuracy: 0.2519\n",
      "Epoch 3/10\n",
      "102/102 [==============================] - 51s 501ms/step - loss: 2.3185 - accuracy: 0.3996 - val_loss: 1.8354 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "102/102 [==============================] - 52s 510ms/step - loss: 1.7251 - accuracy: 0.4051 - val_loss: 1.5481 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "102/102 [==============================] - 52s 510ms/step - loss: 1.5689 - accuracy: 0.3996 - val_loss: 1.4900 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "102/102 [==============================] - 52s 504ms/step - loss: 1.5105 - accuracy: 0.4011 - val_loss: 1.4931 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "102/102 [==============================] - 54s 531ms/step - loss: 1.6001 - accuracy: 0.3959 - val_loss: 1.5017 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "102/102 [==============================] - 54s 530ms/step - loss: 1.5573 - accuracy: 0.3986 - val_loss: 1.4827 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "102/102 [==============================] - 51s 503ms/step - loss: 1.4978 - accuracy: 0.4045 - val_loss: 1.5765 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "102/102 [==============================] - 51s 500ms/step - loss: 1.4936 - accuracy: 0.4017 - val_loss: 1.3943 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "history_2 = model_2.fit(train_generator, validation_data=test_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 3s 263ms/step - loss: 1.3943 - accuracy: 0.4000\n",
      "Test Accuracy for Model_2: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "test_loss_opt, test_acc_opt = model_2.evaluate(test_generator)\n",
    "print(f\"Test Accuracy for Model_2: {test_acc_opt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crop-Disease-Detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
